{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anno_auto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolenair/capstone/blob/master/anno_auto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VmAOqYaqiHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install stanfordnlp\n",
        "# !pip install import_ipynb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIVqPybhrf-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "# import stanfordnlp\n",
        "# import import_ipynb\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFP04bTu27a9",
        "colab_type": "code",
        "outputId": "c13d7dde-4faf-457b-8d84-d80720a673a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bttCQGt0pXdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivTiAhxemm7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
        "# nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6KBg23x7X5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# p = requests.get(\"https://en.wikipedia.org/wiki/Category:20th-century_British_women_writers\")\n",
        "# soup = BeautifulSoup(p.content, \"html.parser\")\n",
        "# authors = soup.findAll(\"div\", { \"class\" : \"mw-category\" })[0].text\n",
        "# auth_list = [i for i in authors.split(\"\\n\") if len(i)>1]\n",
        "\n",
        "# new_url = p + \"&pagefrom=auth_list%2C+Priyanga%0APriyanga+Burford\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OdwJ8jozqWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file = open(\"book.id.gables\")\n",
        "# data = json.load(file)\n",
        "# len(data[\"characters\"][56][\"speaking\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3i7yrFbq3Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "books = [\"gables\", \"avonlea\", \"island\", \"dreams\", \"rilla\" ,\"ingleside\", \"poplars\", \"rainbow\"]\n",
        "urls = [\"https://www.gutenberg.org/files/45/45-0.txt\", \"https://www.gutenberg.org/files/47/47-0.txt\", \"https://www.gutenberg.org/files/51/51-0.txt\", \"http://www.gutenberg.org/cache/epub/544/pg544.txt\", \"http://www.gutenberg.org/cache/epub/3796/pg3796.txt\", \"http://gutenberg.net.au/ebooks01/0100281.txt\", \"http://gutenberg.net.au/ebooks01/0100251.txt\", \"http://www.gutenberg.org/files/5343/5343-0.txt\"]\n",
        "\n",
        "for i in range(len(books)):\n",
        "    page = requests.get(urls[i])\n",
        "    file = open(\"{}.txt\".format(books[i]) , \"w+\")\n",
        "    file.write(page.text)\n",
        "    file.close()\n",
        "\n",
        "file = open(\"gables.txt\", \"r\")\n",
        "gables = file.read()\n",
        "file = open(\"avonlea.txt\", \"r\")\n",
        "avonlea = file.read()\n",
        "file = open(\"island.txt\", \"r\")\n",
        "island = file.read()\n",
        "file = open(\"dreams.txt\", \"r\")\n",
        "dreams = file.read()\n",
        "file = open(\"rilla.txt\", \"r\")\n",
        "rilla = file.read()\n",
        "file = open(\"ingleside.txt\", \"r\")\n",
        "ingleside = file.read()\n",
        "file = open(\"poplars.txt\", \"r\")\n",
        "poplars = file.read()\n",
        "file = open(\"rainbow.txt\", \"r\")\n",
        "rainbow = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnc1YLXPjqSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#agent\n",
        "\n",
        "def return_nsubj2(book, character=\"Anne\"):\n",
        "  sentences_with_agent_Anne = []\n",
        "  sentences_with_agent = []\n",
        "  if book==\"gables\":\n",
        "    doc = nlp(gables)\n",
        "  elif book==\"dreams\":\n",
        "    doc = nlp(dreams)\n",
        "  elif book==\"island\":\n",
        "    doc = nlp(island)\n",
        "  elif book==\"avonlea\":\n",
        "    doc = nlp(avonlea)\n",
        "  elif book==\"rilla\":\n",
        "    doc = nlp(rilla)\n",
        "  elif book==\"ingleside\":\n",
        "    doc = nlp(ingleside)\n",
        "  elif book==\"poplars\":\n",
        "    doc = nlp(poplars)\n",
        "  elif book==\"rainbow\":\n",
        "    doc = nlp(rainbow)\n",
        "  for i in list(doc.sentences):\n",
        "    for e in i.dependencies:\n",
        "  #       print(e[1])\n",
        "      if e[1]==\"nsubj\" or e[1]==\"agent\" :\n",
        "        if e[2].text==character:\n",
        "          sentences_with_agent_Anne.append(\" \".join([i.dependencies[a][2].text for a in range(len(i.dependencies)) if i.dependencies[a][2].text!=character]))\n",
        "        else:\n",
        "          sentences_with_agent.append(\" \".join([i.dependencies[a][2].text for a in range(len(i.dependencies)) if i.dependencies[a][2].text!=character]))\n",
        "        break\n",
        "  target = []\n",
        "  target.extend([[1] for i in range(len(sentences_with_agent_Anne))])\n",
        "  target.extend([[0] for i in range(len(sentences_with_agent))])\n",
        "  sentences = []\n",
        "  sentences.extend([[i] for i in sentences_with_agent_Anne])\n",
        "  sentences.extend([[i] for i in sentences_with_agent])\n",
        "  return sentences, target\n",
        "\n",
        "\n",
        "def return_nsubj(book=\"gables\", p = \"speaking\", tokenid = False):\n",
        "  file = open(\"book.id.{}.book\".format(book))\n",
        "  data = json.load(file)\n",
        "  sentences = []\n",
        "  target = []\n",
        "  for i in range(len(data[\"characters\"])):\n",
        "    if tokenid==True:\n",
        "      sentences.extend([(s[\"w\"], s[\"i\"]) for s in data[\"characters\"][i][p]])\n",
        "    else:\n",
        "      sentences.extend([s[\"w\"] for s in data[\"characters\"][i][p]])\n",
        "    target.extend([data[\"characters\"][i][\"names\"] for e in range(len(data[\"characters\"][i][p]))])\n",
        "      \n",
        "  return [[i] for i in sentences], [[i] for i in target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRxb7G3JscHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file = open(\"book.id.rainbow.book\")\n",
        "# data = json.load(file)\n",
        "# sentences = []\n",
        "# target = []\n",
        "# # print(data[\"characters\"])\n",
        "# for i in range(len(data[\"characters\"])):\n",
        "#   #sentences.extend([s[\"w\"] for s in data[\"characters\"][i][\"speaking\"]])\n",
        "#   #target.extend([data[\"characters\"][i][\"names\"] for e in range(len(data[\"characters\"][i][\"speaking\"]))])\n",
        "#   print(data[\"characters\"][i][\"speaking\"])\n",
        "\n",
        "# full_para_list_rainbow, target_rainbow = [[i] for i in sentences], [[i] for i in target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwL8WyKoO5ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for property_ in [\"speaking\", \"agent\"]:\n",
        "  full_para_list_gables, target_gables = return_nsubj(\"gables\", property_, tokenid = True)\n",
        "  file = open(\"gables_{}withtoken_list.txt\".format(property_), \"w\")\n",
        "  for i in range(len(full_para_list_gables)):\n",
        "    file.write(str(full_para_list_gables[i][0]))\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_gables[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZp1cbQHErV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # data[\"characters\"][1][\"names\"][0]\n",
        "# full_para_list_rainbow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBNwaAjEysJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write to file\n",
        "\n",
        "for property_ in [\"speaking\", \"agent\"]:\n",
        "  full_para_list_gables, target_gables = return_nsubj(\"gables\", property_)\n",
        "  full_para_list_dreams, target_dreams = return_nsubj(\"dreams\", property_)\n",
        "  full_para_list_avonlea, target_avonlea = return_nsubj(\"avonlea\", property_)\n",
        "  full_para_list_island, target_island = return_nsubj(\"island\", property_)\n",
        "  full_para_list_rilla, target_rilla = return_nsubj(\"rilla\", property_)\n",
        "  full_para_list_ingleside, target_ingleside= return_nsubj(\"ingleside\", property_)\n",
        "  full_para_list_poplars, target_poplars = return_nsubj(\"poplars\", property_)\n",
        "  full_para_list_rainbow, target_rainbow = return_nsubj(\"rainbow\", property_)\n",
        "  file = open(\"gables_{}_list.txt\".format(property_), \"w\")\n",
        "  for i in range(len(full_para_list_gables)):\n",
        "    file.write(full_para_list_gables[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_gables[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  #write to file\n",
        "  file = open(\"dreams_{}_list.txt\".format(property_), \"w\")\n",
        "  for i in range(len(full_para_list_dreams)):\n",
        "    file.write(full_para_list_dreams[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_dreams[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  #write to file\n",
        "  file = open(\"avonlea_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_avonlea)):\n",
        "    file.write(full_para_list_avonlea[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_avonlea[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  file = open(\"island_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_island)):\n",
        "    file.write(full_para_list_island[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_island[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  file = open(\"poplars_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_poplars)):\n",
        "    file.write(full_para_list_poplars[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_poplars[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  file = open(\"rilla_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_rilla)):\n",
        "    file.write(full_para_list_rilla[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_rilla[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  file = open(\"rainbow_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_rainbow)):\n",
        "    file.write(full_para_list_rainbow[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_rainbow[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n",
        "\n",
        "  file = open(\"ingleside_{}_list.txt\".format(property_), \"w+\")\n",
        "  for i in range(len(full_para_list_ingleside)):\n",
        "    file.write(full_para_list_ingleside[i][0])\n",
        "    file.write(\"\\n\")\n",
        "    for e in target_ingleside[i][0]:\n",
        "      file.write(str(e[\"c\"])+ \",\" + str(e[\"n\"])+ \",\")\n",
        "    file.write(\"\\n\")\n",
        "  file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksQnJlUm6BVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open(\"book.id.gables.book\")\n",
        "data = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOnGcaea7VCo",
        "colab_type": "code",
        "outputId": "ab40ae0a-d28b-422b-9008-333d276ce678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in data[\"characters\"]:\n",
        "  for e in i[\"names\"]:\n",
        "    if e[\"n\"]==\"Matthew\":\n",
        "      print (i[\"speaking\"])\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEevF5QV8Qqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0384d507-29a4-41a4-b5ec-ab1fc6df7e55"
      },
      "source": [
        "for i in data[\"characters\"]:\n",
        "  for e in i[\"speaking\"]:\n",
        "    if e[\"i\"]==46229:\n",
        "      print(e[\"w\"], e[\"i\"])\n",
        "      break\n",
        "#   if i[\"speaking\"]!=[]:\n",
        "#     print(i[\"speaking\"])\n",
        "#     break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`` acksually never seen anything like it -- it was so white , with awful little red spots in it . ''  46229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo7PgkHGHYSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e88a3ce0-c847-46b7-b42d-19053bd54399"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ5h3QKoEn5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d054ed53-3218-4b71-ab32-034cf09e467e"
      },
      "source": [
        "sents = sent_tokenize(gables)\n",
        "len(sents)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}
